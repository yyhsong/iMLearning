{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性可分和超平面\n",
    "\n",
    "### 二分类\n",
    "\n",
    "- 二分类是一切分类的基础，很多情况下多分类问题可以转化为二分类问题来解决。\n",
    "- 二分类问题就是：给定的各个样本数据分别属于两个类之一，而目标是确定新数据点将归属到哪个类中。\n",
    "\n",
    "### 特征的向量空间模型\n",
    "\n",
    "- 一个个具体的样本，在被机器学习算法处理时，由其特征来表示。\n",
    "- 即每个现实世界的事物，在用来进行机器学习训练或预测时，需要转化为一个特征向量。\n",
    "- 假设样本的特征向量为n维，那么这些样本的特征向量处在n维的特征空间中。\n",
    "- 特征空间可以是欧式空间，也可以是希尔伯特空间。\n",
    "\n",
    "### 线性可分\n",
    "\n",
    "- 选取特征的目的：将一个事物的某些属性数字化，再映射为特征空间中的点，其目的当然是为了对其进行计算。\n",
    "\n",
    "### 超平面\n",
    "\n",
    "- 超平面：n维欧式空间中维度等于n-1的线性子空间。\n",
    "- 将线性可分的样本用超平面分隔开的分类模型，叫做线性分类模型，或线性分类器。\n",
    "- 以最大间隔把两类样本分开的超平面，是最佳超平面，也叫最大间隔超平面。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性可分支持向量机 \n",
    "\n",
    "- 支持向量机 SVM: Support Vector Machine\n",
    "- 线性可分支持向量机就是以找出线性可分的样本在特征空间中的最大间隔超平面为学习目的的分类模型。\n",
    "- SVM的学习目标求解最大间隔超平面问题，其实是一个约束条件下的最优化问题。\n",
    "- 该最优化问题可以使用拉格朗日乘子法进行求解，而不能使用梯度下降法，因为梯度下降法是没有约束条件问题的算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拉格朗日函数\n",
    "\n",
    "- 函数的梯度：表示该函数在某点处的方向导数，方向导数是某个多维函数上的点沿每个维度分别求导后，再组合而成的向量。\n",
    "- 一个函数的梯度与它的等高线垂直。\n",
    "- 拉格朗日函数把原本的目标函数和其限制条件整合成了一个函数。\n",
    "- 于是原本有约束的优化问题，就可以转化为对拉格朗日函数的无约束优化问题。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
