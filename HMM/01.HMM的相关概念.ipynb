{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 概率模型 Probabilistic Model\n",
    "- 所谓概率模型，就是将学习任务归结于计算变量的概率分布的模型。\n",
    "- 推断的本质是：利用可观测变量，来推测未知变量的条件分布。\n",
    "- 逻辑回归、朴素贝叶斯、隐马尔科夫模型和条件随机场CRF都是概率模型。\n",
    "\n",
    "### 生成模型 vs 判别模型\n",
    "- 概率模型又可以分为两类：生成模型（Generative Model）和判别模型（Discriminative Model）。\n",
    "- 既然概率模型是通过可观测变量推断部分未知变量，那么将可观测变量的集合命名为O，将感兴趣的未知变量的集合命名为Y。则生成模型学习出来的是O与Y的联合概率分布 P(O,Y)，而判别模型学习的是条件概率分布：P(Y|O)。\n",
    "- 朴素贝叶斯模型是生成模型，逻辑回归是判别模型。\n",
    "- 在分类问题上，判别模型更有优势，不过生成模型有其专门的用途，HMM是一种生成模型。\n",
    "\n",
    "### 概率图模型 Probabilistic Graphical Model\n",
    "- 概率图模型是一种以图为表示工具，来表达变量间相关关系的概率模型。\n",
    "- 图的概念：一种由节点和连接节点的边组成的数据结构。\n",
    "- 在概率图模型中，一般用节点来表示一个或者一组随机变量，而节点之间的边则表示两个（组）变量之间的概率相关关系。\n",
    "- 边可以是有向（有方向）的，也可以是无向的。概率图模型大致可以分为：\n",
    "    - 有向图模型（贝叶斯网络）：用有向无环图表示变量间的依赖关系\n",
    "    - 无向图模型（马尔可夫网）：用无向图表示变量间的相关关系\n",
    "- HMM是贝叶斯网络的一种，对变量序列建模的贝叶斯网络又叫做动态贝叶斯网络，HMM就是最简单的动态贝叶斯网络。\n",
    "\n",
    "### 马尔科夫链 Markov Chain\n",
    "- 一个随机过程模型，它表述了一系列可能的事件，在这个系列当中每一个事件的概率仅依赖于前一个事件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 隐马尔科夫模型 HMM: Hidden Markov Model\n",
    "\n",
    "### HMM定义\n",
    "- HMM是一个关于时序的概率模型，它的变量分为两组：状态变量和观测变量。\n",
    "- 状态变量和观测变量各自都是一个时间序列，每个状态/观测值都和一个时刻相对应。\n",
    "- 一般假定状态序列是隐藏的、不能被观测到的，因此状态变量是隐变量（Hidden Variable）——这就是 HMM 中 H（Hidden）的来源。\n",
    "- 这个隐藏的、不可观测的状态序列是由一个马尔可夫链随机生成的——这是 HMM 中的第一个 M（Markov）的含义。\n",
    "- 一条隐藏的马尔可夫链随机生成了一个不可观测的状态序列（State Sequence），然后每个状态又对应生成了一个观测结果，这些观测值按照时序排列后就成了观测序列（Observation Sequence）。这两个序列是一一对应的，每个对应的位置又对应着一个时刻。\n",
    "- 一般而言，HMM 的状态变量取值是离散的，而观测变量的取值，则可以是离散的，也可以是连续的。\n",
    "\n",
    "### HMM基本假设\n",
    "HMM 的定义建立在两个假设之上：\n",
    "- 假设1： 假设隐藏的马尔可夫链在任意时刻t的状态只依赖于前一个时刻（t−1时）的状态，与其他时刻的状态及观测无关，也与时刻t无关。这一假设又叫做齐次马尔可夫假设。\n",
    "- 假设2：假设任意时刻的观测只依赖于该时刻的马尔可夫链状态，与其他观测及状态无关。这一假设又叫观测独立性假设。\n",
    "\n",
    "### 确定HMM的两个空间和三组参数\n",
    "- 要确定一个HMM，除了要指定其对应的状态空间和观测空间外，还需要三组参数：\n",
    "    - 状态转移概率：模型在各个状态间转换的概率\n",
    "    - 输出观测概率：模型根据当前状态获得各个观测值的概率\n",
    "    - 初始状态概率：模型在初始时刻各状态出现的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM三个基本问题\n",
    "\n",
    "### 概率计算问题，又称评价（Evaluation）问题\n",
    "- 计算在给定模型下，已知观测序列出现的概率。也就是给定观测序列，求它和评估模型之间的匹配度。\n",
    "\n",
    "### 预测问题，又称解码（Decoding）问题\n",
    "- 计算在给定模型下，使已知观测序列的条件概率最大的状态序列。即给定观测序列，求最有可能与之对应的状态序列。\n",
    "\n",
    "### 学习问题，又称训练（Training）问题\n",
    "- 估计模型参数，使得该模型下观测序列概率最大。也就是训练模型，使其最好地描述观测数据。\n",
    "\n",
    "前两个问题是模型已经存在之后如何使用模型的问题，而最后一个则是如何通过训练得到模型的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 概率计算问题\n",
    "- 前向—后向算法是一种动态规划算法。它分两条路径来计算观测序列概率，一条从前向后（前向），另一条从后向前（后向）。这两条路径，都可以分别计算观测序列出现的概率。\n",
    "- 前向-后向算法其实也可以被看作两个算法：前向算法和后向算法，在实际应用中，选择其中之一来计算即可。\n",
    "\n",
    "### 预测算法\n",
    "- 预测算法是在参数既定，观测序列已知的情况下，找出最有可能产生如此观测序列的状态序列的算法。\n",
    "- 维特比算法：用动态规划求解概率最大路径，是求解HMM预测问题的经典算法。\n",
    "\n",
    "### 学习算法\n",
    "- HMM 的学习算法根据训练数据的不同，可以分为有监督学习和无监督学习两种。\n",
    "- 如果训练数据既包括观测序列，又包括对应的状态序列，且两者之间的对应关系已经明确标注了出来，那么就可以用有监督学习算法。\n",
    "- 如果只有观测序列而没有明确对应的状态序列，就需要用无监督学习算法训练。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
